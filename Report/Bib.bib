@inproceedings{derbel2020AutomaticClassificationAnalysisa,
  title = {Automatic {{Classification}} and {{Analysis}} of {{Multiple-Criteria Decision Making}}},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Sciences}} of {{Electronics}}, {{Technologies}} of {{Information}} and {{Telecommunications}} ({{SETIT}}'18), {{Vol}}.1},
  author = {Derbel, Ahmed and Boujelbene, Younes},
  editor = {Bouhlel, Med Salim and Rovetta, Stefano},
  year = {2020},
  pages = {83--93},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-21005-2_8},
  abstract = {As part of the automatic decision-making process, we propose to highlight the importance of business intelligence and its contribution to management and decision-making in companies. The multi-criteria automatic analysis proposes to set up a complete computer chain that automates all the classic steps of the multi-criteria decision-making. The automatic multi-criteria decision relies mainly on the two learning techniques. Unsupervised classification is used to find two compact and well-separated groups in a dataset. Supervised classification is a learning method for automatically generating rules from a learning database. Both techniques must have existed to produce comprehensive and automatic classification procedures by the user. In this context, we will focus on showing how business intelligence, particularly through data mining and integrated software packages, can be an important decision-support tool for companies.},
  isbn = {978-3-030-21005-2},
  langid = {english}
}

@misc{lemaire2023EfficientShapleyValue,
  title = {An {{Efficient Shapley Value Computation}} for the {{Naive Bayes Classifier}}},
  author = {Lemaire, Vincent and Cl{\'e}rot, Fabrice and Boull{\'e}, Marc},
  year = {2023},
  month = jul,
  number = {arXiv:2307.16718},
  eprint = {2307.16718},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.16718},
  urldate = {2024-10-22},
  abstract = {Variable selection or importance measurement of input variables to a machine learning model has become the focus of much research. It is no longer enough to have a good model, one also must explain its decisions. This is why there are so many intelligibility algorithms available today. Among them, Shapley value estimation algorithms are intelligibility methods based on cooperative game theory. In the case of the naive Bayes classifier, and to our knowledge, there is no ``analytical" formulation of Shapley values. This article proposes an exact analytic expression of Shapley values in the special case of the naive Bayes Classifier. We analytically compare this Shapley proposal, to another frequently used indicator, the Weight of Evidence (WoE) and provide an empirical comparison of our proposal with (i) the WoE and (ii) KernelShap results on real world datasets, discussing similar and dissimilar results. The results show that our Shapley proposal for the naive Bayes classifier provides informative results with low algorithmic complexity so that it can be used on very large datasets with extremely low computation time.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/gianmarco/Zotero/storage/MP3YA3FD/Lemaire et al. - 2023 - An Efficient Shapley Value Computation for the Naive Bayes Classifier.pdf;/Users/gianmarco/Zotero/storage/MV6DYRBJ/2307.html}
}

@article{wickramasinghe2021NaiveBayesApplicationsa,
  title = {Naive {{Bayes}}: Applications, Variations and Vulnerabilities: A Review of Literature with Code Snippets for Implementation},
  shorttitle = {Naive {{Bayes}}},
  author = {Wickramasinghe, Indika and Kalutarage, Harsha},
  year = {2021},
  month = feb,
  journal = {Soft Computing},
  volume = {25},
  number = {3},
  pages = {2277--2293},
  issn = {1433-7479},
  doi = {10.1007/s00500-020-05297-6},
  urldate = {2024-10-22},
  abstract = {Na{\"i}ve Bayes (NB) is a well-known probabilistic classification algorithm. It is a simple but efficient algorithm with a wide variety of real-world applications, ranging from product recommendations through medical diagnosis to controlling autonomous vehicles. Due to the failure of real data satisfying the assumptions of NB, there are available variations of NB to cater general data. With the unique applications for each variation of NB, they reach different levels of accuracy. This manuscript surveys the latest applications of NB and discusses its variations in different settings. Furthermore, recommendations are made regarding the applicability of NB while exploring the robustness of the algorithm. Finally, an attempt is given to discuss the pros and cons of NB algorithm and some vulnerabilities, with related computing code for implementation.},
  langid = {english},
  keywords = {Artificial Intelligence,Machine learning vulnerabilities,Naive Bayes,Probabilistic classification,R code snippets},
  file = {/Users/gianmarco/Zotero/storage/WHGBSICB/Wickramasinghe and Kalutarage - 2021 - Naive Bayes applications, variations and vulnerabilities a review of literature with code snippets.pdf}
}

@article{al2012medical,
  title={Medical data classification with Naive Bayes approach},
  author={Al-Aidaroos, Khadija and Bakar, A Abu and Othman, Z},
  journal={Information Technology Journal},
  volume={11},
  number={9},
  pages={1166--1174},
  year={2012},
  publisher={Asian Network for Scientific Information}
}
@article{nafea2018machine,
  title={Machine learning in educational technology},
  author={Nafea, Ibtehal Talal},
  journal={Machine learning-advanced techniques and emerging applications},
  pages={175--183},
  year={2018},
  publisher={IntechOpen}
}

@inproceedings{derbel2020automatic,
  title={Automatic classification and analysis of multiple-criteria decision making},
  author={Derbel, Ahmed and Boujelbene, Younes},
  booktitle={Proceedings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT’18), Vol. 1},
  pages={83--93},
  year={2020},
  organization={Springer}
}
@online{WeatherDataset,
	title = {Weather Dataset https://2024.aulaweb.unige.it/pluginfile.php/76802/mod\_\\assign/intro/weather.data}
	url = {https://2024.aulaweb.unige.it/pluginfile.php/76802/mod_assign/intro/weather.data},
}
@book{schonlau2023AppliedStatisticalLearning,
  title = {Applied {{Statistical Learning}}: {{With Case Studies}} in {{Stata}}},
  shorttitle = {Applied {{Statistical Learning}}},
  author = {Schonlau, Matthias},
  year = {2023},
  series = {Statistics and {{Computing}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-33390-3},
  urldate = {2024-10-22},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-33389-7 978-3-031-33390-3},
  langid = {english},
  keywords = {Applications in the Social Sciences,Applied Statistical Learning,Case Studies,Data Analytics,Data Science,Data Science Methods in the Social Sciences,Machine Learning,Neural Networks,Random Forests,Stata,Statistical Learning,Support Vector Machines,Text Data,Trees},
  file = {/Users/gianmarco/Zotero/storage/9BUBU8HM/Schonlau - 2023 - Applied Statistical Learning With Case Studies in Stata.pdf}
}

@article{narayan2023EarlyPredictionHeart,
  title = {Early {{Prediction}} of {{Heart Diseases}} Using {{Naive Bayes Classification Algorithm}} and {{Laplace Smoothing Technique}}},
  author = {Narayan, Subhashini and Sathiyamoorthy, E.},
  year = {2023},
  journal = {International Journal of Grid and High Performance Computing},
  volume = {14},
  number = {1},
  pages = {1--14},
  publisher = {IGI Global},
  address = {Hershey, United States},
  issn = {1938-0259},
  doi = {10.4018/IJGHPC.316157},
  urldate = {2024-10-31},
  abstract = {Nowadays, medical diseases are one of the primary causes of death, and it is one the major concerns of developed countries. So, the disease identification process needs a lot of attention since if the diseases are idenfied at the early stage, the rate of death can be decreased. Machine learning techniques is one of the popular approaches that is used for identifying the diseases at the early stage. In this paper, two machine learning techniques, namely Naive Bayes classification algorithm and Laplace smoothing technique are used to predict the heart disease. Here, many medical details are used, such as gender, age, fasting blood sugar, blood pressure, cholesterol, etc. to predict the hearth disease of a patient. The proposed decision system supports avoiding unnecessary diagnosis test, which can be highly beneficial to start the treatment quickly. Thus, both time and money can be saved. Both the performance analysis and the experimental results show the efficiency of the proposed scheme over the existing schemes.},
  copyright = {Copyright {\copyright} 2022, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.},
  langid = {english},
  keywords = {Algorithms,Blood pressure,Cardiovascular disease,Cholesterol,Classification,Data mining,Disease,Heart disease,Heart diseases,Laplace smoothing,Machine learning,Naive bayes,Naive Bayes classifier,Raugh set,Smoothing},
  file = {/Users/gianmarco/Zotero/storage/NKELR4H7/Narayan and Sathiyamoorthy - 2023 - Early Prediction of Heart Diseases using Naive Bayes Classification Algorithm and Laplace Smoothing.pdf}
}
@inproceedings{sabiq2024PerformanceComparisonMultinomial,
  title = {Performance {{Comparison}} of {{Multinomial}} and {{Bernoulli Na{\"i}ve Bayes Algorithms}} with {{Laplace Smoothing Optimization}} in {{Fake News Classification}}},
  booktitle = {2024 {{International Conference}} on {{Artificial Intelligence}}, {{Blockchain}}, {{Cloud Computing}}, and {{Data Analytics}} ({{ICoABCD}})},
  author = {Sabiq, Fikri Fauzan and Rahmatulloh, Alam and Darmawan, Irfan and Rizal, Randi and Gunawan, Rohmat and Haerani, Erna},
  year = {2024},
  month = aug,
  pages = {19--24},
  doi = {10.1109/ICoABCD63526.2024.10704399},
  urldate = {2024-10-31},
  abstract = {In this digital era, there is a lot of information available, one of which is news information. In the dissemination of this news information, there is real news and fake news. This can have a negative impact that can be felt by the public in making decisions based on wrong information and reporting. Therefore, it is important to develop effective methods and algorithms in identifying and classifying fake news. One approach commonly used in fake news classification is the Na{\"i}ve Bayes algorithm. This algorithm is based on probability theory and could classify texts into fake news or real news categories. In Na{\"i}ve Bayes there are several variants that are commonly used, namely the Multinomial Na{\"i}ve Bayes algorithm and the Bernoulli Na{\"i}ve Bayes algorithm. In this research, the two algorithms with and without Laplace smoothing be compared. The difference in accuracy is 0.003\%. The performance of the model using the multinomial na{\"i}ve Bayes algorithm is superior to Bernoulli na{\"i}ve Bayes in terms of accuracy if both do not use Laplace smoothing. However, if Laplace smoothing is carried out on both models, the resulting accuracy has the same value and increases. With a model that uses the multinomial Na{\"i}ve Bayes algorithm, it increases by 0.002\%. Thus, multinomial na{\"i}ve Bayes is better at classifying hoax news than Bernoulli na{\"i}ve Bayes and Laplace smoothing can increase the accuracy of both models.},
  keywords = {Accuracy,Bayes methods,Bernoulli Naive Bayes,Classification algorithms,Cloud computing,Computational modeling,Data analysis,Data models,Fake news,Laplace Smoothing,Multinomial Naive Bayes,Optimization,Smoothing methods},
  file = {/Users/gianmarco/Zotero/storage/3PPCUCTI/Sabiq et al. - 2024 - Performance Comparison of Multinomial and Bernoulli Naïve Bayes Algorithms with Laplace Smoothing Op.pdf}
}
